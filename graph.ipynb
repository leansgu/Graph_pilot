{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE\n",
    " DATALOADER --> GRAPH CONSTRUCTION --> GNN --> EXPLAIN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUB (Dataset):\n",
    "    '''\n",
    "    parts \n",
    "        part_locs \n",
    "        parts (names)\n",
    "    images \n",
    "        200 classes\n",
    "    bounding box  (for cropping images)\n",
    "    classes.txt\n",
    "    train_test_split.txt\n",
    "    image_class_labels.txt\n",
    "    \n",
    "    '''\n",
    "\n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        self.root_dir = root_dir # D:\\TorchProject\\dataset\\cub\\CUB_200_2011\n",
    "        self.transform = transform\n",
    "        self.image_dir = os.path.join(root_dir,'images')\n",
    "        self.image_mapping = self._load_image_mapping()\n",
    "        self.label_mapping = self._load_label_mapping()\n",
    "        self.part_locs_mapping = self._load_part_locs_mapping()\n",
    "        self.part_name_mapping = self._load_part_name_mapping()\n",
    "        self.bounding_box_mapping = self._load_bounding_box()\n",
    "        #self.classes_name = self._load_class_names()\n",
    "    \n",
    "    # def _load_class_names(self):\n",
    "    #     class_names = {}\n",
    "    #     classes_file = os.path.join(self.root_dir,'classes.txt')\n",
    "    #     with open(classes_file, 'r') as file:\n",
    "    #         for line in file:\n",
    "    #             class_id, class_name = line.strip().split()\n",
    "    #             if class_id not in class_names:\n",
    "    #                 class_names[class_id] = {}\n",
    "    #             class_names[class_id] = class_name\n",
    "    #     return class_names\n",
    "\n",
    "    def _load_bounding_box(self):\n",
    "        bounding_box = {}\n",
    "        box_file = os.path.join(self.root_dir, 'bounding_boxes.txt')\n",
    "        with open(box_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, x, y, width, height = line.strip().split()\n",
    "                bounding_box[image_id] = [float(x), float(y), float(width), float(height)]\n",
    "        return bounding_box\n",
    "\n",
    "    def _load_part_name_mapping (self):\n",
    "        part_names = {}\n",
    "        part_names_path = os.path.join(self.root_dir, 'parts', 'parts.txt')\n",
    "        with open(part_names_path, 'r') as file:\n",
    "            for line in file:\n",
    "                part_id, part_name = line.strip().split()\n",
    "                part_names[part_id] = {}\n",
    "                part_names[part_id] = part_name\n",
    "        return part_names\n",
    "              \n",
    "    def _load_part_locs_mapping (self):\n",
    "        part_locs_mapping = {}\n",
    "        part_locs = os.path.join(self.root_dir, 'parts', 'part_locs.txt')\n",
    "        with open(part_locs, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, part_id, x, y, _ = line.strip().split()\n",
    "                if image_id not in part_locs_mapping:\n",
    "                    part_locs_mapping[image_id] = {}\n",
    "                part_locs_mapping[image_id][part_id] = [float (x), float (y)]\n",
    "        return part_locs_mapping\n",
    "\n",
    "    def _load_label_mapping (self):\n",
    "        label_mapping = {}\n",
    "        label_file = os.path.join(self.root_dir,'image_class_labels.txt')\n",
    "        with open(label_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, label_id = line.strip().split()\n",
    "                label_mapping[image_id] = int(label_id)\n",
    "        return label_mapping\n",
    "\n",
    "    def _load_image_mapping (self):\n",
    "        image_mapping = {}\n",
    "        image_file = os.path.join(self.root_dir,'images.txt')\n",
    "        with open(image_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, image_name = line.strip().split()\n",
    "                image_mapping[image_id] = image_name\n",
    "        return image_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_mapping)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.label_mapping[str(index+1)]\n",
    "        part_locs = self.part_locs_mapping.get(str(index), [])\n",
    "        image_name = self.image_mapping[str(index)]\n",
    "        bboxes = self.bounding_box_mapping.get(str(index), [])\n",
    "        #part_name = self.part_name_mapping.get(str(index),[])\n",
    "        image= Image.open(os.path.join(self.image_dir,image_name)).convert('RGB')\n",
    "        \n",
    "        # Didnt check if this task is done right, because no need to be in here currently \n",
    "        # class_names_list= []\n",
    "        # class_names = self.class_names.get(str(index), [])\n",
    "        # for int (i) in class_names:\n",
    "        #     class_names_list.append(class_names[i])\n",
    "        \n",
    "        part_name_list = []\n",
    "        part_name_dict = {}\n",
    "        for key in part_locs:\n",
    "            part_name = self.part_name_mapping.get(str(key),[])\n",
    "            part_name_dict[part_name] = part_locs[key]\n",
    "            part_name_list.append(part_name)\n",
    "\n",
    "        if self.transform:\n",
    "           image = self.transform(image)\n",
    "#        return (image, label,part_name, part_locs, bboxes, part_name_list, part_name_dict)\n",
    "        return (image, label, part_locs, bboxes, part_name_dict) #, class_names    # why has to have part_locs to display right the location?\n",
    "    # dict: 'back': [0.0, 0.0],'beak': [312.0, 182.0], 'belly': [0.0, 0.0], 'breast': [0.0, 0.0], 'crown': [186.0, 45.0],..\n",
    "    # locs: '8': [0.0, 0.0], '9': [0.0, 0.0], '10': [100.0, 221.0], '11': [183.0, 101.0], '12': [0.0, 0.0], '13': [0.0, 0.0], .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=RGB size=500x335 at 0x21F2BE433D0>, 1, {'1': [0.0, 0.0], '2': [312.0, 182.0], '3': [0.0, 0.0], '4': [0.0, 0.0], '5': [186.0, 45.0], '6': [247.0, 79.0], '7': [0.0, 0.0], '8': [0.0, 0.0], '9': [0.0, 0.0], '10': [100.0, 221.0], '11': [183.0, 101.0], '12': [0.0, 0.0], '13': [0.0, 0.0], '14': [0.0, 0.0], '15': [215.0, 194.0]}, [60.0, 27.0, 325.0, 304.0], {'back': [0.0, 0.0], 'beak': [312.0, 182.0], 'belly': [0.0, 0.0], 'breast': [0.0, 0.0], 'crown': [186.0, 45.0], 'forehead': [247.0, 79.0], 'left_eye': [0.0, 0.0], 'left_leg': [0.0, 0.0], 'left_wing': [0.0, 0.0], 'nape': [100.0, 221.0], 'right_eye': [183.0, 101.0], 'right_leg': [0.0, 0.0], 'right_wing': [0.0, 0.0], 'tail': [0.0, 0.0], 'throat': [215.0, 194.0]})\n"
     ]
    }
   ],
   "source": [
    "### for testing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "root_dir = 'D:\\TorchProject\\dataset\\cub\\CUB_200_2011'\n",
    "# run dataset == __init__\n",
    "dataset = CUB(root_dir) # --> load sample to check\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False) #divide dataset by batch\n",
    "image, label, part_locs, bboxes, part_name_dict = dataset[1]\n",
    "\n",
    "print(dataset[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def visualize_bounding_box(image, part_name_dict, bboxes):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Extract bounding box coordinates\n",
    "    x, y, width, height = bboxes\n",
    "    rect_pb = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "    ax.add_patch(rect_pb)\n",
    "    # Iterate over part bounding boxes and draw rectangles\n",
    "    for part_id, part_bb in part_name_dict.items():\n",
    "        x_pb, y_pb = part_bb\n",
    "        width_pb, height_pb = 5, 5  # Modify the width and height as per your requirement\n",
    "        rect_pb = patches.Rectangle((x_pb, y_pb), width_pb, height_pb, linewidth=1, edgecolor='b', facecolor='none')\n",
    "        ax.add_patch(rect_pb)\n",
    "\n",
    "        # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "root_dir = 'D:\\TorchProject\\dataset\\cub\\CUB_200_2011'\n",
    "# run dataser == __init__\n",
    "dataset = CUB(root_dir) # --> load sample to check\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False) #divide dataset by batch\n",
    "\n",
    "# call len  == __len__\n",
    "print (len(dataset))\n",
    "\n",
    "for i in range (1,10):\n",
    "    image, label, part_locs, bboxes, part_name_dict = dataset[i]\n",
    "    print (label,part_name_dict, part_locs,bboxes)\n",
    "\n",
    "    # Visualize all bounding boxes\n",
    "    visualize_bounding_box(image, part_locs, bboxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Class names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the classes for embedding text \n",
    "\n",
    "root_dir = 'D:\\TorchProject\\dataset\\cub\\CUB_200_2011'\n",
    "\n",
    "CLASS_NAMES = {}\n",
    "classes_file = os.path.join(root_dir,'classes.txt')\n",
    "with open(classes_file, 'r') as file:\n",
    "    for line in file:\n",
    "        class_id, class_name = line.strip().split()\n",
    "        if class_id not in CLASS_NAMES:\n",
    "            CLASS_NAMES[class_id] = {}\n",
    "        CLASS_NAMES[class_id] = class_name\n",
    "print(CLASS_NAMES)\n",
    "\n",
    "for i in range (1,201):\n",
    "    print (CLASS_NAMES[str(i)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding by BERT\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class TextEmbedder:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    def embed_text(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling over tokens\n",
    "        return embeddings\n",
    "    \n",
    "    \n",
    "### Test \n",
    "# Initialize the TextEmbedder\n",
    "text_embedder = TextEmbedder()\n",
    "\n",
    "embedded_class_names = {}\n",
    "# Example class names\n",
    "for i in range (1,len(CLASS_NAMES)+1):\n",
    "#range(1,201):\n",
    "    embedded_class_names[i] = (text_embedder.embed_text(CLASS_NAMES[str(i)]))\n",
    "\n",
    "# Print the embeddings\n",
    "print(embedded_class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check embedded tensor \n",
    "\n",
    "#len(embedded_class_names)\n",
    "#embedded_class_names[100]\n",
    "embedded_class_names[1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Construction\n",
    "- Node (1 -> 15)\n",
    "- Node (16 -> 216)\n",
    "- Edges (init)\n",
    "\n",
    "- load the class names from classes.txt file\n",
    "- embedding each class name (each node) \n",
    "- put each embedded name into each node (from 16 to 216) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph construction\n",
    "import networkx as nx\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class Graph_construct:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.Graph()\n",
    "  \n",
    "\n",
    "    def add_nodes(self, part_locs):\n",
    "        # Add nodes from 1st to 15th with their attributes\n",
    "        for i in range(1, 16):\n",
    "            x, y = part_locs[str(i)] # Replace with actual position (x, y) data if available\n",
    "            title = f\"Node {i}\"\n",
    "            image_tensor = torch.rand(16, 16)  # Replace with actual image tensor data if available\n",
    "\n",
    "            node_attributes = {\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"title\": title,\n",
    "                \"image\": image_tensor ## wait for ViT to split\n",
    "            }\n",
    "\n",
    "            self.graph.add_node(i, **node_attributes)\n",
    "\n",
    "        # Add nodes from 16th to the rest with their class_name attribute\n",
    "        # num_classes = 200  # Replace with the actual number of classes in the dataset\n",
    "\n",
    "        text_embedder = TextEmbedder()\n",
    "\n",
    "        embedded_class_names = {}\n",
    "        for i in range (1,len(CLASS_NAMES)+1):\n",
    "            embedded_class_names[i] = (text_embedder.embed_text(CLASS_NAMES[str(i)]))\n",
    "\n",
    "        for i in range(16, 216):\n",
    "            node_attributes = {\"class_name\": embedded_class_names[(i - 15)]}\n",
    "            self.graph.add_node(i, **node_attributes)\n",
    "\n",
    "    def calculate_edges(self):\n",
    "        # Calculate edges for nodes from 1st to 15th based on distance between (x, y) positions\n",
    "        for i in range(1, 16):\n",
    "            for j in range(i + 1, 16):\n",
    "                x1, y1 = self.graph.nodes[i][\"x\"], self.graph.nodes[i][\"y\"]\n",
    "                x2, y2 = self.graph.nodes[j][\"x\"], self.graph.nodes[j][\"y\"]\n",
    "                distance = ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n",
    "                self.graph.add_edge(i, j, weight=distance)\n",
    "\n",
    "        # Set edges from nodes 16th to the rest to others nodes = 1 for the initial step\n",
    "        for i in range(16, 216):\n",
    "            for j in range(1, 16):\n",
    "                self.graph.add_edge(i, j, weight=1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = 'D:\\TorchProject\\dataset\\cub\\CUB_200_2011'\n",
    "    # run dataser == __init__\n",
    "    dataset = CUB(root_dir)\n",
    "    \n",
    "    graph_construct = Graph_construct()\n",
    "\n",
    "    graph_construct.add_nodes(dataset[2][2]) # dataset -> image, label, part_locs, \n",
    "    graph_construct.calculate_edges()\n",
    "\n",
    "    # You can access the graph object with all nodes and edges\n",
    "    G = graph_construct.graph\n",
    "    print(G.nodes(data=True))\n",
    "    print(G.edges(data=True))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class TextEmbedder:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    def embed_text(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling over tokens\n",
    "        return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Parts_name should be embedded to put in the node or be used as the label (for level 1: detect the parts of the birds)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
