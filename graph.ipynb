{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms \n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUB (Dataset):\n",
    "    '''\n",
    "    parts \n",
    "        part_locs \n",
    "        parts \n",
    "    images \n",
    "        200 classes\n",
    "    classes.txt\n",
    "    train_test_split.txt\n",
    "    image_class_labels.txt\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        self.root_dir = root_dir # D:\\TorchProject\\dataset\\cub\\CUB_200_2011\n",
    "        self.transform = transform\n",
    "        self.image_dir = os.path.join(root_dir,'images')\n",
    "        self.image_mapping = self._load_image_mapping()\n",
    "        self.label_mapping = self._load_label_mapping()\n",
    "        self.bbox_mapping = self._load_bbox_mapping ()\n",
    "        self.attribute_mapping = self._load_attribute_mapping()\n",
    "        self.part_bbox_mapping = self._load_part_bbox_mapping()\n",
    "        self.part_locs_mapping = self._load_part_locs_mapping()\n",
    "\n",
    "    def _load_part_locs_mapping (self):\n",
    "        part_locs_mapping = {}\n",
    "        part_locs = os.path.join(self.root_dir, 'parts', 'part_locs.txt')\n",
    "        with open(part_locs, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, part_id, x, y, visible = line.strip().split()\n",
    "                if visible == '1':\n",
    "                    if image_id not in part_locs_mapping:\n",
    "                        part_locs_mapping[image_id] = {}\n",
    "                    part_locs_mapping[image_id][part_id] = [float(x), float(y)]\n",
    "                    part_locs_mapping[image_id]['visible'] = float(visible)\n",
    "        return part_locs_mapping\n",
    "\n",
    "    def _load_label_mapping (self): # why \"_load_...\" ? --> chi dung trong class nay, k call dc tu ben ngoai\n",
    "        label_mapping = {}\n",
    "        label_file = os.path.join(self.root_dir,'image_class_labels.txt')\n",
    "        with open(label_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, label_id = line.strip().split()\n",
    "                label_mapping[image_id] = int(label_id)\n",
    "        return label_mapping\n",
    "\n",
    "    def _load_image_mapping (self):\n",
    "        image_mapping = {}\n",
    "        image_file = os.path.join(self.root_dir,'images.txt')\n",
    "        with open(image_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, image_name = line.strip().split()\n",
    "                image_mapping[image_id] = image_name\n",
    "        return image_mapping\n",
    "\n",
    "    def _load_bbox_mapping (self):\n",
    "        bbox_mapping = {}\n",
    "        bbox_file = os.path.join(self.root_dir,'bounding_boxes.txt')\n",
    "        with open(bbox_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, x, y, width, height = line.strip().split()\n",
    "\n",
    "                bbox_mapping[image_id] = [float (x), float (y), float (width), float (height)]\n",
    "        return bbox_mapping\n",
    "\n",
    "    def _load_attribute_mapping(self):\n",
    "        attribute_mapping = {}\n",
    "        attribute_file = os.path.join(self.root_dir, 'attributes', 'image_attribute_labels.txt')\n",
    "        with open(attribute_file, 'r') as file:\n",
    "            for line in file:\n",
    "                if len((line.strip().split())) != 5:\n",
    "                    image_id, attribute_id, is_present, _, _, _ = line.strip().split()\n",
    "                else:\n",
    "                    image_id, attribute_id, is_present, _, _= line.strip().split()\n",
    "                if image_id not in attribute_mapping:\n",
    "                    attribute_mapping[image_id] = []\n",
    "                attribute_mapping[image_id].append(attribute_id)\n",
    "        return attribute_mapping\n",
    "\n",
    "    def _load_part_bbox_mapping(self):\n",
    "        part_bbox_mapping = {}\n",
    "        part_bbox_file = os.path.join(self.root_dir, 'parts', 'part_locs_test.txt')\n",
    "        with open(part_bbox_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_id, part_id, x, y, visible = line.strip().split()\n",
    "                if visible == '1':\n",
    "                    if image_id not in part_bbox_mapping:\n",
    "                        part_bbox_mapping[image_id] = {}\n",
    "                    part_bbox_mapping[image_id][part_id] = [float(x), float(y)]\n",
    "        return part_bbox_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_mapping)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#        label = self.label_mapping[str(index+1)]\n",
    "#        bbox = self.bbox_mapping[str(index+1)]\n",
    "#        attribute = self.attribute_mapping.get(str(index), [])\n",
    "#        part_bbox = self.part_bbox_mapping.get(str(index), {})\n",
    "#        part_locs = self.part_bbox_mapping.get(str(index), [])\n",
    "#        image_name = self.image_mapping[str(index)]\n",
    "        \n",
    "        label = self.label_mapping[str(index+1)]\n",
    "        part_locs = self.part_bbox_mapping.get(str(index), [])\n",
    "        image_name = self.image_mapping[str(index)]\n",
    "        print(image_name)\n",
    "\n",
    "        image= Image.open(os.path.join(self.image_dir,image_name)).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "           image = self.transform(image)\n",
    "        return (image, label, part_locs)\n",
    "#        return (image, label, bbox, attribute, part_bbox, part_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11788\n",
      "001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m# indexing in  dataset == __getitem__\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m# Get the image and bounding box at the specified index\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39m#image,label,bbox,attribute,part_bbox = dataset[10]\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m1\u001b[39m,\u001b[39m10\u001b[39m):\n\u001b[0;32m     54\u001b[0m \u001b[39m#    image,label,bbox,attribute,part_bbox, part_locs = dataset[i]\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     image,label,bbox, part_bbox,part_locs \u001b[39m=\u001b[39m dataset[i]\n\u001b[0;32m     57\u001b[0m     \u001b[39mprint\u001b[39m (label,bbox,part_locs)\n\u001b[0;32m     59\u001b[0m     \u001b[39m# Visualize all bounding boxes\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 3)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "def visualize_bounding_box(image, bbox, part_bbox, part_locs):\n",
    "        # Create figure and axes\n",
    "        fig, ax = plt.subplots(1)\n",
    "\n",
    "        # Display the image\n",
    "        ax.imshow(image)\n",
    "\n",
    "    # Extract bounding box coordinates\n",
    "        x, y, width, height = bbox\n",
    "        #x, y, width, height = box\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "        # Add the rectangle to the plot\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "        # Iterate over part bounding boxes and draw rectangles\n",
    "        for part_id, part_bb in part_bbox.items():\n",
    "            x_pb, y_pb = part_bb\n",
    "            width_pb, height_pb = 5, 5  # Modify the width and height as per your requirement\n",
    "\n",
    "            rect_pb = patches.Rectangle((x_pb, y_pb), width_pb, height_pb, linewidth=1, edgecolor='b', facecolor='none')\n",
    "\n",
    "            ax.add_patch(rect_pb)\n",
    "\n",
    "            # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "root_dir = 'D:\\TorchProject\\dataset\\cub\\CUB_200_2011'\n",
    "# run dataser == __init__\n",
    "dataset = CUB(root_dir) # --> load sample to check\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False) #divide dataset by batch\n",
    "\n",
    "# call len  == __len__\n",
    "print (len(dataset))\n",
    "\n",
    "# indexing in  dataset == __getitem__\n",
    "# Get the image and bounding box at the specified index\n",
    "#image,label,bbox,attribute,part_bbox = dataset[10]\n",
    "\n",
    "for i in range (1,10):\n",
    "#    image,label,bbox,attribute,part_bbox, part_locs = dataset[i]\n",
    "    image,label,bbox, part_bbox,part_locs = dataset[i]\n",
    "\n",
    "    print (label,bbox,part_locs)\n",
    "\n",
    "    # Visualize all bounding boxes\n",
    "    visualize_bounding_box(image, bbox, part_bbox, part_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_graph (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super (simple_graph, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3) \n",
    "        self.d1 = nn.Linear(224*224*32, 128)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "        #x = nn.Linear(5,5)\n",
    "\n",
    "    def forward (self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
